{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyOFRYrCR2oVoj4S1/iKPBkL"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"XPNrEUzyBahr"},"source":["# **Age Detection with OpenCV**\n","\n","![대체 텍스트](https://www.pyimagesearch.com/wp-content/uploads/2020/04/opencv_age_detection_examples.jpg)\n","\n","sypically, you’ll see age detection implemented as a two-stage process:\n","\n","\n","\n","1.   Detect faces in the input image/video stream\n","2.   Extract the face Region of Interest (ROI), and apply the age detector algorithm to predict the age of the person\n","\n","Age detector modle\n","\n","![대체 텍스트](https://www.pyimagesearch.com/wp-content/uploads/2020/04/opencv_age_detection_arch.png)"]},{"cell_type":"code","source":["#@title Import Libraries\n","# import the necessary packages\n","import os\n","import numpy as np\n","import cv2\n","import google.colab.patches\n","\n","# For downloading the image.\n","import matplotlib.pyplot as plt\n","import tempfile\n","import six.moves.urllib.request \n","import six \n","import PIL\n","\n","import base64, logging\n","import io\n","import IPython.display\n","import google.colab.output"],"metadata":{"cellView":"form","id":"y5zKqA_dupLo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y4VKjszDFksA"},"source":["Download the pre-trained detection models, consisting of under files:\n",">\n","* 1.Face Detection Model\n","* 2.Age Detection Model\n","* 3.Gender Detection Model"]},{"cell_type":"code","metadata":{"id":"HK28KwzHGnMk","cellView":"form"},"source":["#@title Load data and model\n","%%shell\n","mkdir ageDetection; cd ageDetection\n","mkdir model; cd model\n","curl -LJO https://github.com/phoebe81/DetectionWithOpenCV/raw/master/Model/face_deploy.prototxt \n","curl -LJO https://github.com/phoebe81/DetectionWithOpenCV/raw/master/Model/face_deploy.caffemodel\n","\n","curl -LJO https://github.com/phoebe81/DetectionWithOpenCV/raw/master/Model/age_deploy.prototxt\n","curl -LJO https://github.com/phoebe81/DetectionWithOpenCV/raw/master/Model/age_deploy.caffemodel\n","\n","curl -LJO https://github.com/phoebe81/DetectionWithOpenCV/raw/master/Model/gender_deploy.prototxt\n","curl -LJO https://github.com/phoebe81/DetectionWithOpenCV/raw/master/Model/gender_deploy.caffemodel\n","\n","cd ..; mkdir images; cd images\n","curl -LJO https://github.com/phoebe81/DetectionWithOpenCV/raw/master/Images/jangnara.jpg \n","curl -LJO https://github.com/phoebe81/DetectionWithOpenCV/raw/master/Images/jangnara2.jpg \n","\n","cd ..;mkdir videos; cd videos\n","curl -LJO https://github.com/phoebe81/DetectionWithOpenCV/raw/master/Videos/JJANG.mp4\n","cd videos\n","mkdir save"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x5xenljzI3Ss"},"source":["# Root directory \n","ROOT_DIR = os.path.abspath(\"./ageDetection/\")\n","# Model directory \n","MODEL_DIR = os.path.join(ROOT_DIR, \"model\")\n","# Images directory\n","IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")\n","\n","# Video directory\n","VIDEO_DIR = os.path.join(ROOT_DIR, \"videos\")\n","VIDEO_SAVE_DIR = os.path.join(VIDEO_DIR, \"save\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Face\n","prototxtPath = os.path.sep.join([MODEL_DIR, \"face_deploy.prototxt\"])  \n","weightsPath = os.path.sep.join([MODEL_DIR, \"face_deploy.caffemodel\"]) \n","faceNet = cv2.dnn.readNetFromCaffe(prototxtPath, weightsPath)\n","# faceNet= cv2.dnn.readNet(weightsPath, prototxtPath,\"caffe\")\n","\n","#Age\n","prototxtPath = os.path.sep.join([MODEL_DIR, \"age_deploy.prototxt\"])  \n","weightsPath = os.path.sep.join([MODEL_DIR, \"age_deploy.caffemodel\"]) \n","ageNet = cv2.dnn.readNetFromCaffe(prototxtPath, weightsPath)\n","# ageNet= cv2.dnn.readNet(weightsPath, prototxtPath,\"caffe\")\n","\n","#Gender\n","prototxtPath = os.path.sep.join([MODEL_DIR, \"gender_deploy.prototxt\"])  \n","weightsPath = os.path.sep.join([MODEL_DIR, \"gender_deploy.caffemodel\"]) \n","genderNet = cv2.dnn.readNetFromCaffe(prototxtPath, weightsPath)\n","# genderNet= cv2.dnn.readNet(weightsPath, prototxtPath,\"caffe\")"],"metadata":{"id":"KouW96uXvWMk"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qm4A3XchhjWL"},"source":["#Age and Gender classification list\n","AGE_LIST = [\"(0-2)\", \"(4-6)\", \"(8-12)\", \"(15-20)\", \"(25-32)\", \"(38-43)\", \"(48-53)\", \"(60-100)\"]\n","GENDER_LIST = ['Male', 'Female']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1rKl_gaSMqA6"},"source":["# **1**.Detection model demo by picture"]},{"cell_type":"code","source":["#@title Select an Input Image\n","SAMPLE_IMAGE = 'jangnara2.jpg' #@param {type:\"string\"}\n","IMAGE_URL = 'https://www.bollywoodhungama.com/wp-content/uploads/2020/06/BTS-members-look-heavenly-in-head-to-toe-Prada-collection-on-the-August-cover-of-Vogue-Japan-.jpg'  #@param {type:\"string\"}\n","\n","def display_image(image):\n","  fig = plt.figure(figsize=(20, 15))\n","  plt.grid(False)\n","  plt.imshow(image)\n","\n","def download_and_resize_image(url,display=False):\n","  _, filename = tempfile.mkstemp(suffix=\".jpg\")\n","  response = six.moves.urllib.request.urlopen(url)\n","  image_data = response.read()\n","  image_data = six.BytesIO(image_data)\n","  pil_image = PIL.Image.open(image_data)\n","  pil_image_rgb = pil_image.convert(\"RGB\")\n","  pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n","  print(f\"Image downloaded to {filename}.\")\n","  if display:\n","    display_image(pil_image)\n","  return filename\n","\n","if len(IMAGE_URL) !=0 :\n","  IMAGE_URL = download_and_resize_image(IMAGE_URL)\n","if len(SAMPLE_IMAGE) !=0 :\n","  SAMPLE_URL = os.path.join(IMAGE_DIR, SAMPLE_IMAGE)\n","\n","image_url = IMAGE_URL or SAMPLE_URL"],"metadata":{"id":"04540CjRwAwI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Apply Detection model"],"metadata":{"id":"zKPQ8xUgwYxf"}},{"cell_type":"code","source":["def detect_and_predict_age(frame,conf_threshold=0.5):\n","  (high, width) = frame.shape[:2]\n","\n","  blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300),(104.0, 177.0, 123.0))\t\t\n","  faceNet.setInput(blob)\n","  detections = faceNet.forward()\n","\n","  for i in range(0, detections.shape[2]):\n","    confidence = detections[0, 0, i, 2]\n","    if confidence > conf_threshold:\n","\n","\t\t\t# extract the ROI of the face\n","      box = detections[0, 0, i, 3:7] * np.array([width, high, width, high])\n","      (startX, startY, endX, endY) = box.astype(\"int\")\t\t\t\n","      face = frame[startY:endY, startX:endX]\t\t\t\n","      if face.shape[0] < 20 or face.shape[1] < 20:\n","        continue\n","\n","      #Age prediction and display\n","      faceBlob = cv2.dnn.blobFromImage(face, 1.0, (227, 227),(78.4263377603, 87.7689143744, 114.895847746),swapRB=False)\n","      ageNet.setInput(faceBlob)\n","      preds = ageNet.forward()\n","      arg = preds[0].argmax()\n","      age = AGE_LIST[arg]\n","      ageConfidence = preds[0][arg]\n","      ageText = f\"{age}: {ageConfidence * 100:.2f}%\"\n","\n","\t\t\t#Gender prediction and display\n","      genderNet.setInput(faceBlob)\n","      preds = genderNet.forward()\n","      arg = preds[0].argmax()\n","      gender = GENDER_LIST[arg]\n","      genderConfidence = preds[0][arg]\n","      genderText = f\"{gender}: {genderConfidence * 100:.2f}%\"\n","\n","\t\t\t# draw the bounding box of the face along with the associated probability\n","      y = startY - 30 if startY - 30 > 30 else startY + 30\n","      cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 0, 255), 2)\n","      cv2.putText(frame, genderText, (startX, y),cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n","      cv2.putText(frame, ageText, (startX, y+15),cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)"],"metadata":{"id":"rH-rQzj2wkMc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image = cv2.imread(image_url)\n","detect_and_predict_age(image)\n","google.colab.patches.cv2_imshow(image)"],"metadata":{"id":"bI8rXP5txPAG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uHzPJ6VdRPB4"},"source":["# **2**.Detection model demo by video"]},{"cell_type":"code","source":["#@title Videdo Capture\n","# Using a webcam to capture images for processing on the runtime.\n","# Source: https://colab.research.google.com/notebooks/snippets/advanced_outputs.ipynb#scrollTo=2viqYx97hPMi\n","\n","def data_uri_to_img(uri):\n","  try:\n","    image = base64.b64decode(uri.split(',')[1], validate=True)\n","    # make the binary image, a PIL image\n","    image = PIL.Image.open(io.BytesIO(image))\n","    # convert to numpy array\n","    image = np.array(image, dtype=np.uint8);\n","    return image\n","  except Exception as e:\n","    logging.exception(e)\n","    print('\\n')\n","    return None\n","\n","def video_to_data_url(filename):\n","    ext = filename.split('.')[-1]\n","    prefix = f\"data:video/{ext};base64,\"\n","    with open(filename, 'rb') as f:\n","        vidoe = f.read()\n","    return prefix + base64.b64encode(vidoe).decode()\n","\n","# from base64 import b64decode\n","# playing webcam or video with javascript\n","def take_photo(filename='photo.jpg', quality=0.8):\n","  js = IPython.display.Javascript('''     \n","    async function takePhoto(filename, quality) {\n","                  \n","      const div = document.createElement('div');\n","      document.body.appendChild(div);\n","\n","      const exit = document.createElement('button');\n","      exit.textContent = 'Exit';\n","      div.appendChild(exit);\n","\n","      const video = document.createElement('video');\n","      video.style.display = 'block';\n","           \n","      if('photo.jpg' == filename){\n","        const stream = await navigator.mediaDevices.getUserMedia({video: true}); \n","        video.srcObject = stream;   \n","      }else{\n","        video.src = filename;\n","        video.type=\"video/mp4\"\n","      }\n","      await video.play();  \n","      div.appendChild(video);       \n","                   \n","\n","      // Resize the output to fit the video element.\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","      \n","      let jsLog = function(abc) {\n","        document.querySelector(\"#output-area\").appendChild(document.createTextNode(`${abc}... `));\n","      }\n","\n","      // when Exit button is clicked.   \n","      var isOpened = true; \n","      var exitPromise = new Promise((resolve) => {exit.onclick = resolve});   \n","      exitPromise.then(()=>{isOpened = false; stream.getVideoTracks()[0].stop();});\n","      \n","      //when end of video\n","      var endPromise = new Promise((resolve) => {video.onended = resolve});   \n","      endPromise.then(()=>{isOpened = false; video.stop();});\n","\n","      const canvas = document.createElement('canvas');\n","      canvas.width = video.videoWidth;\n","      canvas.height = video.videoHeight;\n","\n","      for (let i = 0; isOpened; i++) {\n","        canvas.getContext(\"2d\").clearRect(0, 0, canvas.width, canvas.height);\n","        canvas.getContext('2d').drawImage(video, 0, 0);\n","        img = canvas.toDataURL('image/jpeg', quality);\n","\n","        // jsLog(i + \"sending\");\n","        // Call a python function and send this image\n","        google.colab.kernel.invokeFunction('notebook.run_ageDetection', [img], {});\n","        // jsLog(i + \"SENT\");\n","\n","        // wait for X miliseconds second, before next capture\n","        await new Promise(resolve => setTimeout(resolve, 250));        \n","      }       \n","      div.remove();      \n","    }    \n","    ''')  \n","  # make the provided HTML, part of the cell\n","  IPython.display.display(js)\n","  #call the takePhoto() JavaScript function\n","  google.colab.output.eval_js(f\"takePhoto('{filename}',{quality})\")\n","\n","frame_count = 0\n","writer = None\n","# InvokeFunction\n","# takes the numpy image and runs detection, then shows the results by visualizing\n","def run_ageDetection(uri): \n","  global frame_count, writer\n","\n","  image = data_uri_to_img(uri)     \n","  if writer is None:\t\t\n","      fourcc = cv2.VideoWriter_fourcc(*'DIVX')  \n","      writer = cv2.VideoWriter(outVideo, fourcc, 2, (image.shape[1], image.shape[0]), True)\n","  try:        \n","    detect_and_predict_age(image)\n","\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n","    frame_count+=1    \n","    name = f\"{frame_count}.jpg\"\n","    name = os.path.join(VIDEO_SAVE_DIR, name)\n","    cv2.imwrite(name, image)\n","\n","    if writer is not None:\n","      writer.write(image)\n","  except Exception as e:\n","    logging.exception(e)\n","    print('\\n')\n","\n","# register this function, so JS code could call this\n","google.colab.output.register_callback('notebook.run_ageDetection', run_ageDetection)"],"metadata":{"cellView":"form","id":"p1HRlmfV0IG3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iupDbgy9SXYv"},"source":["## Apply Detection model"]},{"cell_type":"code","metadata":{"id":"2qHP85SjjXPw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669901548865,"user_tz":-540,"elapsed":448,"user":{"displayName":"유은정","userId":"11867406313502038872"}},"outputId":"12a385cf-259c-4789-abc2-d747483f8a56"},"source":["%%shell\n","cd ageDetection\n","rm ./videos/save/* \n","rm ./videos/out.avi"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"AqVfPuqSSWsI"},"source":["inVideo = os.path.join(VIDEO_DIR, \"JJANG.mp4\")\n","outVideo= os.path.join(VIDEO_DIR, \"out.avi\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tyEoH1mHSaLK","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1669901596661,"user_tz":-540,"elapsed":20228,"user":{"displayName":"유은정","userId":"11867406313502038872"}},"outputId":"109e18d2-0006-4196-fb98-d8d867981bbe"},"source":["frame_count = 0\n","# data_url = video_to_data_url(inVideo)\n","data_url = 'photo.jpg'\n","try: \n","  # put the JS code in cell and run it\n","  take_photo(data_url)  \n","  if writer is not None:\n","    writer.release()   \n","except Exception as e:\n","  logging.exception(e)\n","  print('\\n')\n","\n","writer = None"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["     \n","    async function takePhoto(filename, quality) {\n","                  \n","      const div = document.createElement('div');\n","      document.body.appendChild(div);\n","\n","      const exit = document.createElement('button');\n","      exit.textContent = 'Exit';\n","      div.appendChild(exit);\n","\n","      const video = document.createElement('video');\n","      video.style.display = 'block';\n","           \n","      if('photo.jpg' == filename){\n","        const stream = await navigator.mediaDevices.getUserMedia({video: true}); \n","        video.srcObject = stream;   \n","      }else{\n","        video.src = filename;\n","        video.type=\"video/mp4\"\n","      }\n","      await video.play();  \n","      div.appendChild(video);       \n","                   \n","\n","      // Resize the output to fit the video element.\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","      \n","      let jsLog = function(abc) {\n","        document.querySelector(\"#output-area\").appendChild(document.createTextNode(`${abc}... `));\n","      }\n","\n","      // when Exit button is clicked.   \n","      var isOpened = true; \n","      var exitPromise = new Promise((resolve) => {exit.onclick = resolve});   \n","      exitPromise.then(()=>{isOpened = false; stream.getVideoTracks()[0].stop();});\n","      \n","      //when end of video\n","      var endPromise = new Promise((resolve) => {video.onended = resolve});   \n","      endPromise.then(()=>{isOpened = false; video.stop();});\n","\n","      const canvas = document.createElement('canvas');\n","      canvas.width = video.videoWidth;\n","      canvas.height = video.videoHeight;\n","\n","      for (let i = 0; isOpened; i++) {\n","        canvas.getContext(\"2d\").clearRect(0, 0, canvas.width, canvas.height);\n","        canvas.getContext('2d').drawImage(video, 0, 0);\n","        img = canvas.toDataURL('image/jpeg', quality);\n","\n","        // jsLog(i + \"sending\");\n","        // Call a python function and send this image\n","        google.colab.kernel.invokeFunction('notebook.run_ageDetection', [img], {});\n","        // jsLog(i + \"SENT\");\n","\n","        // wait for X miliseconds second, before next capture\n","        await new Promise(resolve => setTimeout(resolve, 250));        \n","      }       \n","      div.remove();      \n","    }    \n","    "]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"5_xMRmi0Sdmy"},"source":["## Downlod  video\n"]},{"cell_type":"code","metadata":{"id":"aCpG7Qj8Sc6E","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1669901601214,"user_tz":-540,"elapsed":7,"user":{"displayName":"유은정","userId":"11867406313502038872"}},"outputId":"03b7c304-6aa5-4113-fc3d-a5009cce3fda"},"source":["from google.colab import files\n","files.download(outVideo)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_86220098-f2e8-443f-8d8a-4b7bd817c0f1\", \"out.avi\", 786432)"]},"metadata":{}}]}]}