{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"YOLO object detection with OpenCV.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOqSHa95yi1zkD2QtGE3Oz1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"T3K-34Y-MA3-","colab_type":"text"},"source":["# **YOLO object detection with OpenCV**\n","![대체 텍스트](https://s3-us-west-2.amazonaws.com/static.pyimagesearch.com/opencv-yolo/yolo_car_chase_01_output.gif)\n","\n","What is the YOLO object detector?\n","\n","![대체 텍스트](http://media5.datahacker.rs/2019/04/yolo_diagram-1024x556.jpg)\n","\n","We can say that the basic idea of the Yolo algorithm is applying both the image classification and localization algorithm on each of nine grid cells. \n","![대체 텍스트](http://media5.datahacker.rs/2018/11/025_02.png)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"0ssfb0pwMisl","colab_type":"text"},"source":["# Data Load of image, video and model"]},{"cell_type":"code","metadata":{"id":"NDBLks3lMN5Z","colab_type":"code","colab":{}},"source":["%%shell\n","mkdir objectDetection; cd objectDetection\n","mkdir model; cd model\n","curl -LJO https://github.com/phoebe81/DetectionWithOpenCV/raw/master/Model/coco.names\n","curl -LJO https://github.com/phoebe81/DetectionWithOpenCV/raw/master/Model/yolov3.cfg\n","curl -LJO https://github.com/phoebe81/DetectionWithOpenCV/raw/master/Model/yolov3.weights\n","cd ..; mkdir images; cd images\n","curl -LJO https://github.com/phoebe81/DetectionWithOpenCV/raw/master/Images/example_01.jpg\n","curl -LJO https://github.com/phoebe81/DetectionWithOpenCV/raw/master/Images/example_02.jpg\n","curl -LJO https://github.com/phoebe81/DetectionWithOpenCV/raw/master/Images/example_03.jpg\n","curl -LJO https://github.com/phoebe81/DetectionWithOpenCV/raw/master/Images/example_04.jpg\n","curl -LJO https://github.com/phoebe81/DetectionWithOpenCV/raw/master/Images/example_05.jpg\n","curl -LJO https://github.com/phoebe81/DetectionWithOpenCV/raw/master/Images/example_06.jpg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8lLUgwC2V9RJ","colab_type":"code","colab":{}},"source":["# import the necessary packages\n","import numpy as np\n","import cv2\n","from google.colab.patches import cv2_imshow\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3CYMYsEdNDYY","colab_type":"code","colab":{}},"source":["# Root directory of the project\n","ROOT_DIR = os.path.abspath(\"./objectDetection/\")\n","# Directory to save logs and trained model\n","MODEL_DIR = os.path.join(ROOT_DIR, \"model\")\n","# Directory of images/video to run detection on\n","IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")\n","\n","weightsPath = os.path.sep.join([MODEL_DIR, \"yolov3.weights\"])\n","configPath = os.path.sep.join([MODEL_DIR, \"yolov3.cfg\"])\n","objectNet = cv2.dnn.readNetFromDarknet(configPath, weightsPath)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JosmucotOPOM","colab_type":"code","colab":{}},"source":["# determine only the *output* layer names that we need from YOLO\n","ln = objectNet.getLayerNames()\n","ln = [ln[i[0] - 1] for i in objectNet.getUnconnectedOutLayers()]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CX8jqjlfRoa-","colab_type":"code","colab":{}},"source":["confThreshold  = 0.3\n","nmsThreshold = 0.3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iTl-4KN5NRNh","colab_type":"code","colab":{}},"source":["# load the COCO class labels our YOLO model was trained on\n","labelsPath = os.path.sep.join([MODEL_DIR, \"coco.names\"])\n","LABELS = open(labelsPath).read().strip().split(\"\\n\")\n","np.random.seed(42)\n","COLORS = np.random.randint(0, 255, size=(len(LABELS), 3),dtype=\"uint8\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9wCZmitFN3fv","colab_type":"text"},"source":["# **1**.Detection model demo by picture"]},{"cell_type":"code","metadata":{"id":"6o50TdllN-F6","colab_type":"code","colab":{}},"source":["# load the input image\n","image_list = []\n","layerOutputs_list = []\n","for file in os.listdir(IMAGE_DIR):\n","\tfile_path = os.path.join(IMAGE_DIR, file)\n","\tif(os.path.isfile(file_path)): \n","\t\timage = cv2.imread(file_path)\n","\t\tblob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n","\t\tobjectNet.setInput(blob)\t\n","\t\tlayerOutputs = objectNet.forward(ln)  \n","\t\timage_list.append(image)   \n","\t\tlayerOutputs_list.append(layerOutputs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"92MK05WgRZvC","colab_type":"code","colab":{}},"source":["for i, layerOutputs in enumerate(layerOutputs_list):\n","\tboxes = []\n","\tconfidences = []\n","\tclassIDs = []\n","\t(H, W) = image_list[i].shape[:2]\n","\timage = image_list[i]\n","\tfor output in layerOutputs:\t\t\n","\t\tfor detection in output:\n","\t\t\tscores = detection[5:]\t\t\n","\t\t\tclassID = np.argmax(scores)\n","\t\t\tconfidence = scores[classID]\n","\n","\t\t\tif confidence > confThreshold:\n","\t\t\t\tbox = detection[0:4] * np.array([W, H, W, H])\n","\t\t\t\t(centerX, centerY, width, height) = box.astype(\"int\")\n","\n","\t\t\t\tx = int(centerX - (width / 2))\n","\t\t\t\ty = int(centerY - (height / 2))\n","\n","\t\t\t\tboxes.append([x, y, int(width), int(height)])\n","\t\t\t\tconfidences.append(float(confidence))\n","\t\t\t\tclassIDs.append(classID)\n","\t# apply non-maxima suppression to suppress weak, overlapping bounding boxes\n","\tidxs = cv2.dnn.NMSBoxes(boxes, confidences, confThreshold, nmsThreshold)\n","\n","\t# ensure at least one detection exists\n","\tif len(idxs) > 0:\n","\t\tfor i in idxs.flatten():\n","\t\t\t(x, y) = (boxes[i][0], boxes[i][1])\n","\t\t\t(w, h) = (boxes[i][2], boxes[i][3])\n","\n","\t\t\tcolor = [int(c) for c in COLORS[classIDs[i]]]\n","\t\t\tcv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n","\t\t\ttext = \"{}: {:.4f}\".format(LABELS[classIDs[i]], confidences[i])\n","\t\t\tcv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fSBEMxcqRegB","colab_type":"code","colab":{}},"source":["# show the output image\n","for image in image_list:\n","  cv2_imshow(image)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i8LRhJyD6kuw","colab_type":"text"},"source":["# **2**.Detection model demo by video"]},{"cell_type":"code","metadata":{"id":"oqkvb1VG6lzo","colab_type":"code","colab":{}},"source":["%%shell\n","cd objectDetection\n","mkdir videos; cd videos\n","curl -LJO https://github.com/phoebe81/DetectionWithOpenCV/raw/master/Videos/car_chase_01.mp4\n","cd videos; mkdir save"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZW8hNk20VIzQ","colab_type":"code","colab":{}},"source":["VIDEO_DIR = os.path.join(ROOT_DIR, \"videos\")\n","VIDEO_SAVE_DIR = os.path.join(VIDEO_DIR, \"save\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CBetASXnVOPr","colab_type":"text"},"source":["## Processing Funtions"]},{"cell_type":"code","metadata":{"id":"a_QAyouaVMmN","colab_type":"code","colab":{}},"source":["import base64, logging\n","import numpy as np\n","from PIL import Image\n","from io import BytesIO\n","\n","def data_uri_to_img(uri):\n","  try:\n","    image = base64.b64decode(uri.split(',')[1], validate=True)\n","    # make the binary image, a PIL image\n","    image = Image.open(BytesIO(image))\n","    # convert to numpy array\n","    image = np.array(image, dtype=np.uint8); \n","    return image\n","  except Exception as e:\n","    logging.exception(e);print('\\n')\n","    return None\n","\n","def video_to_data_url(filename):\n","    ext = filename.split('.')[-1]\n","    prefix = 'data:video/{};base64,'.format(ext)\n","    with open(filename, 'rb') as f:\n","        vidoe = f.read()\n","    return prefix + base64.b64encode(vidoe).decode()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q3oW6XfLVZbc","colab_type":"code","colab":{}},"source":["def detect_and_predict_object(frame):\n","\tblob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n","\tobjectNet.setInput(blob)\n","\tlayerOutputs = objectNet.forward(ln)\n","\t\n","\tboxes = []\n","\tconfidences = []\n","\tclassIDs = []\n","\tfor output in layerOutputs:\t\t\n","\t\tfor detection in output:\n","\t\t\tscores = detection[5:]\t\t\n","\t\t\tclassID = np.argmax(scores)\n","\t\t\tconfidence = scores[classID]\n","\n","\t\t\tif confidence > confThreshold:\n","\t\t\t\tbox = detection[0:4] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])\n","\t\t\t\t(centerX, centerY, width, height) = box.astype(\"int\")\n","\n","\t\t\t\tx = int(centerX - (width / 2))\n","\t\t\t\ty = int(centerY - (height / 2))\n","\n","\t\t\t\tboxes.append([x, y, int(width), int(height)])\n","\t\t\t\tconfidences.append(float(confidence))\n","\t\t\t\tclassIDs.append(classID)\n","\t# apply non-maxima suppression to suppress weak, overlapping bounding boxes\n","\tidxs = cv2.dnn.NMSBoxes(boxes, confidences, confThreshold, nmsThreshold)\n","\n","\t# ensure at least one detection exists\n","\tif len(idxs) > 0:\n","\t\tfor i in idxs.flatten():\n","\t\t\t(x, y) = (boxes[i][0], boxes[i][1])\n","\t\t\t(w, h) = (boxes[i][2], boxes[i][3])\n","\n","\t\t\tcolor = [int(c) for c in COLORS[classIDs[i]]]\n","\t\t\tcv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n","\t\t\ttext = \"{}: {:.4f}\".format(LABELS[classIDs[i]], confidences[i])\n","\t\t\tcv2.putText(frame, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BqnoTK1CWcVY","colab_type":"text"},"source":["\n","## Videdo Capture\n","Using a webcam to capture images for processing on the runtime.\n","Source: https://colab.research.google.com/notebooks/snippets/advanced_outputs.ipynb#scrollTo=2viqYx97hPMi"]},{"cell_type":"code","metadata":{"id":"fedtCcHRWZvZ","colab_type":"code","colab":{}},"source":["from IPython.display import display, Javascript\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","\n","# playing webcam or video with javascript\n","def take_photo(filename='photo.jpg', quality=0.8):\n","  js = Javascript('''     \n","    async function takePhoto(filename, quality) {\n","                  \n","      const div = document.createElement('div');\n","      document.body.appendChild(div);\n","\n","      const exit = document.createElement('button');\n","      exit.textContent = 'Exit';\n","      div.appendChild(exit);\n","\n","      const video = document.createElement('video');\n","      video.style.display = 'block';\n","           \n","      if('photo.jpg' == filename){\n","        const stream = await navigator.mediaDevices.getUserMedia({video: true}); \n","        video.srcObject = stream;   \n","      }else{\n","        video.src = filename;\n","        video.type=\"video/mp4\"\n","      }\n","      await video.play();  \n","      div.appendChild(video);       \n","                   \n","\n","      // Resize the output to fit the video element.\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","      \n","      let jsLog = function(abc) {\n","        document.querySelector(\"#output-area\").appendChild(document.createTextNode(`${abc}... `));\n","      }\n","\n","      // when Exit button is clicked.   \n","      var isOpened = true; \n","      var exitPromise = new Promise((resolve) => {exit.onclick = resolve});   \n","      exitPromise.then(()=>{isOpened = false; stream.getVideoTracks()[0].stop();});\n","      \n","      //when end of video\n","      var endPromise = new Promise((resolve) => {video.onended = resolve});   \n","      endPromise.then(()=>{isOpened = false; video.stop();});\n","\n","      const canvas = document.createElement('canvas');\n","      canvas.width = video.videoWidth;\n","      canvas.height = video.videoHeight;\n","\n","      for (let i = 0; isOpened; i++) {\n","        canvas.getContext(\"2d\").clearRect(0, 0, canvas.width, canvas.height);\n","        canvas.getContext('2d').drawImage(video, 0, 0);\n","        img = canvas.toDataURL('image/jpeg', quality);\n","\n","        // jsLog(i + \"sending\");\n","        // Call a python function and send this image\n","        google.colab.kernel.invokeFunction('notebook.run_objectDetection', [img], {});\n","        // jsLog(i + \"SENT\");\n","\n","        // wait for X miliseconds second, before next capture\n","        await new Promise(resolve => setTimeout(resolve, 250));        \n","      }       \n","      div.remove();      \n","    }    \n","    ''')  \n","  # make the provided HTML, part of the cell\n","  display(js)\n","  #call the takePhoto() JavaScript function\n","  eval_js('takePhoto({},{})'.format(\"'\"+filename+\"'\", quality)) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g-j-d_XVWXNi","colab_type":"code","colab":{}},"source":["from google.colab import output\n","frame_count = 0\n","writer = None\n","\n","# InvokeFunction\n","# takes the numpy image and runs detection, then shows the results by visualizing\n","def run_objectDetection(uri): \n","  global frame_count, writer\n","\n","  image = data_uri_to_img(uri)     \n","  if writer is None:\t\t\n","      fourcc = cv2.VideoWriter_fourcc(*'DIVX')  \n","      writer = cv2.VideoWriter(outVideo, fourcc, 2, (image.shape[1], image.shape[0]), True)\n","  try:        \n","    detect_and_predict_object(image)\n","\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n","    frame_count+=1    \n","    name = '{0}.jpg'.format(frame_count)\n","    name = os.path.join(VIDEO_SAVE_DIR, name)\n","    cv2.imwrite(name, image)\n","\n","    if writer is not None:\n","      writer.write(image)\n","  except Exception as e:\n","    logging.exception(e)\n","    print('\\n')\n","\n","# register this function, so JS code could call this\n","output.register_callback('notebook.run_objectDetection', run_faceDetection)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UEFe8Ps7W-0_","colab_type":"text"},"source":["## Apply Detection model"]},{"cell_type":"code","metadata":{"id":"pZnYjg_uWrzj","colab_type":"code","colab":{}},"source":[" %%shell\n"," cd faceDection\n"," rm ./videos/save/* \n"," rm ./videos/out.avi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DP0brvv7XA7f","colab_type":"code","colab":{}},"source":["inVideo = os.path.join(VIDEO_DIR, \"car_chase_01.mp4\")\n","outVideo= os.path.join(VIDEO_DIR, \"out.avi\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v7amtFg6XW28","colab_type":"code","colab":{}},"source":["frame_count = 0\n","data_url = video_to_data_url(inVideo)\n","try: \n","  # put the JS code in cell and run it\n","  take_photo()  \n","  if writer is not None:\n","    writer.release()   \n","except Exception as e:\n","  logging.exception(e)\n","  print('\\n')\n","\n","writer = None"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vEaVVWOfXawY","colab_type":"text"},"source":["## Downlod  to our local machine"]},{"cell_type":"code","metadata":{"id":"6v-NuTJQXaXD","colab_type":"code","colab":{}},"source":["from google.colab import files\n","files.download(outVideo)"],"execution_count":null,"outputs":[]}]}